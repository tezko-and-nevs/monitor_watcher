# 🚀 MaqOCR - Modern Document Intelligence Engine

![Version](https://img.shields.io/badge/version-2.1.0-blue.svg)
![Next.js](https://img.shields.io/badge/Next.js-15.0+-black?logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue?logo=typescript)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**MaqOCR** is a high-performance optical character recognition and document analysis system built with modern web technologies. Leveraging **WebAssembly** and **Machine Learning** models for real-time document processing.

## ✨ Features

- 🎯 **Multi-format Support** - PDF, JPG, PNG, TIFF with auto-detection
- ⚡ **WASM-Powered** - Near-native performance in browser
- 🧠 **AI-Powered Parsing** - Intelligent layout analysis and text extraction
- 🔒 **Privacy First** - All processing happens client-side
- 📊 **Batch Processing** - Concurrent document handling with queue management

## 🛠 Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | Next.js 15, TypeScript, Tailwind CSS |
| **Processing** | WebAssembly, TensorFlow.js, OpenCV.js |
| **Storage** | IndexedDB, Cloud Storage SDK |
| **Utils** | PDF.js, Tesseract.js, Sharp WASM |

## 🚀 Quick Start

```bash
# Clone repository
git clone https://github.com/maq-ai/maqocr.git
cd maqocr

# Install dependencies
npm install

# Start development server
npm run dev

# Build for production
npm run build
```

## 📖 Usage Examples

```typescript
import { MaqOCR } from '@maq-ai/ocr-core';

const ocr = new MaqOCR({
  model: 'high-accuracy',
  language: 'auto-detect',
  outputFormat: 'markdown'
});

const result = await ocr.processDocument(file);
console.log(result.text);
console.log(result.confidence);
```

## 🏗 Architecture

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Document      │ -> │   Preprocessing  │ -> │   OCR Engine    │
│   Input         │    │   (WASM)         │    │   (ML Model)    │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Format        │    │   Image          │    │   Text          │
│   Detection     │    │   Enhancement    │    │   Extraction    │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

## 🔧 Configuration

Create `.env.local`:

```env
MAQ_OCR_MODEL_PATH=/models/standard
MAQ_STORAGE_BUCKET=maq-ocr-cache
MAQ_API_ENDPOINT=https://api.maq.ai/v1/process
MAQ_MAX_FILE_SIZE=50MB
```

## 📊 Performance Benchmarks

| Document Type | Processing Time | Accuracy |
|---------------|-----------------|----------|
| Scanned PDF   | 2.3s            | 98.7%    |
| Camera Image  | 1.8s            | 95.2%    |
| Screenshot    | 0.9s            | 99.1%    |

## 🤝 Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) and read our [Code of Conduct](CODE_OF_CONDUCT.md).

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🆘 Support

- 📧 Email: support@maq.ai
- 🐛 Issues: [GitHub Issues](https://github.com/maq-ai/maqocr/issues)
- 💬 Discussions: [GitHub Discussions](https://github.com/maq-ai/maqocr/discussions)

---

<div align="center">
  
**Made with ❤️ by the MaqAI Team**

[Website](https://maq.ai) • [Documentation](https://docs.maq.ai) • [Blog](https://blog.maq.ai)

</div>
